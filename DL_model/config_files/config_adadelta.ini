; last training: 10/05/2023
[general]
; comment to disable
wandb_enable = yes
wandb_notes = train final model using Adadelta insted of Adam optimizer
; if training == 0 only run validation once:
training = yes
testing = yes
;debug_mode = yes


[training]
run_name = adadelta
;run_name = ... <- other run with same config file
;load_run_name = TEST
load_epoch = 0
train_epochs = 100000
;criterion = nll_loss
;criterion = focal_loss
criterion = lovasz_softmax
lr_start = 1e-1
ignore_frames_loss = 6
; only for focal loss and summed losses:
;gamma = 5
; only for summed losses:
;w = 0.5
cuda = yes
optimizer = adadelta

save_every = 10000
test_every = 5000
print_every = 1000

[dataset]
relative_path = ../data/sparks_dataset
dataset_size = full
;dataset_size = minimal
;batch_size = 2
batch_size = 4
num_workers = 0
data_duration = 256
data_stride = 32
data_smoothing = no
norm_video = abs_max
;norm_video = chunk
;remove_background = moving
remove_background = no
;only_sparks = no
;noise_data_augmentation = no
sparks_type = raw
;sparks_type = peaks
inference = overlap


[network]
nn_architecture = pablos_unet
;nn_architecture = github_unet
unet_steps = 6
first_layer_channels = 8
;temporal_reduction = no
;num_channels = 1
;dilation = 1
border_mode = same
;batch_normalization = batch
batch_normalization = none
initialize_weights = no
attention = no
up_mode = transpose


[testing]
; these are not used in the 'training.py' script
t_sparks = 0.65
t_puffs = 0.65
t_waves = 0.6
sparks_min_radius = 0
puffs_min_radius = 5
waves_min_radius = 0
; use this params to validate the unet
batch_size = 1
dataset_size = full
;dataset_size = minimal
load_epoch = 100000
inference = overlap
data_duration = 256
data_stride = 32


[unused]
;fixed_threshold = 0.9
;t_detection_sparks = 0.9
;t_detection_puffs = 0.9
;t_detection_waves = 0.9
;sparks_min_radius = 2
;puffs_min_radius = 2
;waves_min_radius = 2
