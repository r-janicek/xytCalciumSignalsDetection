{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Prediction Script\n",
    "\n",
    "Script that uses the function `get_final_preds` to get predictions from a movie path or from a movie array in numpy format. The function will be integrated in the GUI developped in Matlab by Rado.\n",
    "\n",
    "The function uses a (trained) UNet model to perform image segmentation and returns the segmentation and instances arrays.\n",
    "\n",
    "Author: Prisca Dotti  \n",
    "Last Modified: 23.10.2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload is used to reload modules automatically before entering the\n",
    "# execution of code typed at the IPython prompt.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# To import modules from parent directory in Jupyter Notebook\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prisc\\anaconda3\\envs\\sparks\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import imageio\n",
    "import napari\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from config import TrainingConfig, config\n",
    "from utils.training_inference_tools import get_final_preds\n",
    "from utils.training_script_utils import init_model\n",
    "from utils.visualization_tools import (\n",
    "    get_annotations_contour,\n",
    "    get_discrete_cmap,\n",
    "    get_labels_cmap,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters that are necessary to configure the dataset and the UNet model (can be eventually hard-coded in the function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:51] [  INFO  ] [   config   ] <290 > -- Loading C:\\Users\\prisc\\Code\\sparks_project\\config_files\\config_final_model.ini\n"
     ]
    }
   ],
   "source": [
    "### Set training-specific parameters ###\n",
    "\n",
    "# Initialize training-specific parameters\n",
    "config_path = os.path.join(\"config_files\", \"config_final_model.ini\")\n",
    "params = TrainingConfig(training_config_file=config_path)\n",
    "params.run_name = \"final_model\"\n",
    "model_filename = f\"network_100000.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the model, as it was trained with DataParallel. Wrapping it in DataParallel and retrying...\n",
      "Network should be on CPU, removing DataParallel wrapper...\n"
     ]
    }
   ],
   "source": [
    "### Configure UNet ###\n",
    "# params.set_device(device=\"auto\")\n",
    "params.set_device(device=\"cpu\")  # temporary\n",
    "\n",
    "network = init_model(params=params)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "if params.device.type != \"cpu\":\n",
    "    network = nn.DataParallel(network).to(params.device, non_blocking=True)\n",
    "    # cudnn.benchmark = True\n",
    "\n",
    "### Load UNet model ###\n",
    "\n",
    "# Path to the saved model checkpoint\n",
    "models_relative_path = os.path.join(\n",
    "    \"models\", \"saved_models\", params.run_name, model_filename\n",
    ")\n",
    "model_dir = os.path.realpath(os.path.join(config.basedir, models_relative_path))\n",
    "\n",
    "# Load the model state dictionary\n",
    "try:\n",
    "    network.load_state_dict(torch.load(model_dir, map_location=params.device))\n",
    "except RuntimeError as e:\n",
    "    if \"module\" in str(e):\n",
    "        # The error message contains \"module,\" so handle the DataParallel loading\n",
    "        print(\n",
    "            \"Failed to load the model, as it was trained with DataParallel. Wrapping it in DataParallel and retrying...\"\n",
    "        )\n",
    "        # Get current device of the object (model)\n",
    "        temp_device = next(iter(network.parameters())).device\n",
    "\n",
    "        network = nn.DataParallel(network)\n",
    "        network.load_state_dict(torch.load(model_dir, map_location=params.device))\n",
    "\n",
    "        print(\"Network should be on CPU, removing DataParallel wrapper...\")\n",
    "        network = network.module.to(temp_device)\n",
    "    else:\n",
    "        # Handle other exceptions or re-raise the exception if it's unrelated\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define movie path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_path = r\"C:\\Users\\prisc\\Code\\sparks_project\\data\\sparks_dataset\\05_video.tif\"\n",
    "\n",
    "# movie_path = r\"C:\\Users\\dotti\\Desktop\\cropped 34_video.tif\"\n",
    "# shape is (904, 53, 284)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run sample in U-Net (using the function `get_final_preds`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.eval()\n",
    "segmentation, instances = get_final_preds(\n",
    "    model=network,\n",
    "    params=params,\n",
    "    movie_path=movie_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save predicted segmentation and instances on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if movie_path is not None:\n",
    "    # Get the movie filename\n",
    "    movie_filename = os.path.splitext(os.path.basename(movie_path))[0]\n",
    "else:\n",
    "    # If no movie is provided, use a generic name\n",
    "    movie_filename = \"sample_movie\"\n",
    "\n",
    "# Set the output directory\n",
    "out_dir = os.path.join(config.basedir, \"evaluation\", \"matlab_inference_script\")\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Save the segmentation and instances on disk as .tif files\n",
    "imageio.volwrite(\n",
    "    os.path.join(out_dir, f\"{movie_filename}_unet_segmentation.tif\"),\n",
    "    np.uint8(segmentation),\n",
    ")\n",
    "imageio.volwrite(\n",
    "    os.path.join(out_dir, f\"{movie_filename}_unet_instances.tif\"), np.uint8(instances)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize U-Net's predictions with Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'instances' at 0x2585fdbfdf0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open original movie\n",
    "sample = np.asarray(imageio.volread(movie_path))\n",
    "# set up napari parameters\n",
    "cmap = get_discrete_cmap(name=\"gray\", lut=16)\n",
    "labels_cmap = get_labels_cmap()\n",
    "# visualize only border of classes (segmentation array)\n",
    "segmentation_border = get_annotations_contour(segmentation)\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(\n",
    "    sample,\n",
    "    name=\"input movie\",\n",
    "    # colormap=('colors',cmap)\n",
    ")\n",
    "\n",
    "viewer.add_labels(\n",
    "    segmentation_border,\n",
    "    name=\"segmentation\",\n",
    "    opacity=0.9,\n",
    "    color=labels_cmap,\n",
    ")  # only visualize border\n",
    "\n",
    "viewer.add_labels(\n",
    "    segmentation,\n",
    "    name=\"segmentation\",\n",
    "    opacity=0.5,\n",
    "    color=labels_cmap,\n",
    "    visible=False,\n",
    ")  # to visualize whole roi instead\n",
    "\n",
    "viewer.add_labels(\n",
    "    instances,\n",
    "    name=\"instances\",\n",
    "    opacity=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
